{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18ce83a0-9805-40b6-ac81-2565933568f7",
   "metadata": {},
   "source": [
    "# Assignment 2\n",
    "### Daniel Mehta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a4ace4b-36dc-4367-b987-5deb4cd8ce3f",
   "metadata": {},
   "source": [
    "## Exercise 1: [POS (Part-of-Speech) Tagging with Hidden Markov Model](https://www.mygreatlearning.com/blog/pos-tagging/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d0da7e7-1033-42fd-b6bf-db9e5118a69b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pprint, time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "450d15e9-fcc7-48fe-8f61-74cf922702b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package treebank to\n",
      "[nltk_data]     /Users/danielmehta/nltk_data...\n",
      "[nltk_data]   Package treebank is already up-to-date!\n",
      "[nltk_data] Downloading package universal_tagset to\n",
      "[nltk_data]     /Users/danielmehta/nltk_data...\n",
      "[nltk_data]   Package universal_tagset is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Pierre', 'NOUN')\n",
      "('Vinken', 'NOUN')\n",
      "(',', '.')\n",
      "('61', 'NUM')\n",
      "('years', 'NOUN')\n",
      "('old', 'ADJ')\n",
      "(',', '.')\n",
      "('will', 'VERB')\n",
      "('join', 'VERB')\n",
      "('the', 'DET')\n",
      "('board', 'NOUN')\n",
      "('as', 'ADP')\n",
      "('a', 'DET')\n",
      "('nonexecutive', 'ADJ')\n",
      "('director', 'NOUN')\n",
      "('Nov.', 'NOUN')\n",
      "('29', 'NUM')\n",
      "('.', '.')\n",
      "('Mr.', 'NOUN')\n",
      "('Vinken', 'NOUN')\n",
      "('is', 'VERB')\n",
      "('chairman', 'NOUN')\n",
      "('of', 'ADP')\n",
      "('Elsevier', 'NOUN')\n",
      "('N.V.', 'NOUN')\n",
      "(',', '.')\n",
      "('the', 'DET')\n",
      "('Dutch', 'NOUN')\n",
      "('publishing', 'VERB')\n",
      "('group', 'NOUN')\n",
      "('.', '.')\n"
     ]
    }
   ],
   "source": [
    "nltk.download('treebank')\n",
    "nltk.download('universal_tagset')\n",
    "nltk_data = list(nltk.corpus.treebank.tagged_sents(tagset='universal'))\n",
    "for sent in nltk_data[:2]:\n",
    "  for tuple in sent:\n",
    "    print(tuple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b08a223f-f77a-4fb2-82df-07ab804606f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split training and validation\n",
    "train_set,test_set =train_test_split(nltk_data,train_size=0.80,test_size=0.20,random_state = 101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b572687-ff24-439b-a8d0-2a3e40cbc95f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80310\n",
      "20366\n"
     ]
    }
   ],
   "source": [
    "train_tagged_words = [ tup for sent in train_set for tup in sent ]\n",
    "test_tagged_words = [ tup for sent in test_set for tup in sent ]\n",
    "print(len(train_tagged_words))\n",
    "print(len(test_tagged_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f9f074df-d400-4c12-aa42-05c83dc59cf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Drink', 'NOUN'),\n",
       " ('Carrier', 'NOUN'),\n",
       " ('Competes', 'VERB'),\n",
       " ('With', 'ADP'),\n",
       " ('Cartons', 'NOUN')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tagged_words[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e2d785b-6a3f-4df1-9939-b7c2ff6f7ea3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "{'ADJ', 'NUM', 'PRON', 'ADP', 'CONJ', 'VERB', 'NOUN', 'DET', 'PRT', 'X', 'ADV', '.'}\n"
     ]
    }
   ],
   "source": [
    "tags = {tag for word,tag in train_tagged_words}\n",
    "print(len(tags))\n",
    "print(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cccf1b44-de10-4f7a-8b53-b2b5a27beb46",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = {word for word,tag in train_tagged_words}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "03a46411-85f1-4bb5-82d2-12b5aa4b4ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute emission probability\n",
    "def word_given_tag(word, tag, train_bag = train_tagged_words):\n",
    "    tag_list = [pair for pair in train_bag if pair[1]==tag]\n",
    "    count_tag = len(tag_list)\n",
    "    w_given_tag_list = [pair[0] for pair in tag_list if pair[0]==word]\n",
    "    count_w_given_tag = len(w_given_tag_list)\n",
    "     \n",
    "    return (count_w_given_tag, count_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f2b0ebf7-64e1-4997-9e22-5a09a2001738",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute transition probability\n",
    "def t2_given_t1(t2, t1, train_bag = train_tagged_words):\n",
    "    tags = [pair[1] for pair in train_bag]\n",
    "    count_t1 = len([t for t in tags if t==t1])\n",
    "    count_t2_t1 = 0\n",
    "    for index in range(len(tags)-1):\n",
    "        if tags[index]==t1 and tags[index+1]== t2:\n",
    "            count_t2_t1 += 1\n",
    "    return (count_t2_t1, count_t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b626e5c5-8888-4105-b262-285f912572ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6.33009672e-02 2.17475723e-02 1.94174761e-04 8.05825219e-02\n",
      "  1.68932043e-02 1.14563107e-02 6.96893215e-01 5.24271838e-03\n",
      "  1.14563107e-02 2.09708735e-02 5.24271838e-03 6.60194159e-02]\n",
      " [3.53445187e-02 1.84219927e-01 1.42806140e-03 3.74866128e-02\n",
      "  1.42806144e-02 2.07068902e-02 3.51660132e-01 3.57015361e-03\n",
      "  2.60621198e-02 2.02427700e-01 3.57015361e-03 1.19243130e-01]\n",
      " [7.06150308e-02 6.83371304e-03 6.83371304e-03 2.23234631e-02\n",
      "  5.01138950e-03 4.84738052e-01 2.12756261e-01 9.56719834e-03\n",
      "  1.41230067e-02 8.83826911e-02 3.69020514e-02 4.19134386e-02]\n",
      " [1.07061505e-01 6.32751212e-02 6.96026310e-02 1.69577319e-02\n",
      "  1.01240189e-03 8.47886596e-03 3.23588967e-01 3.20931405e-01\n",
      "  1.26550242e-03 3.45482156e-02 1.45532778e-02 3.87243740e-02]\n",
      " [1.13611415e-01 4.06147093e-02 6.03732169e-02 5.59824370e-02\n",
      "  5.48847427e-04 1.50384188e-01 3.49066973e-01 1.23490669e-01\n",
      "  4.39077942e-03 9.33040585e-03 5.70801310e-02 3.51262353e-02]\n",
      " [6.63904250e-02 2.28360966e-02 3.55432779e-02 9.23572779e-02\n",
      "  5.43278083e-03 1.67955801e-01 1.10589318e-01 1.33609578e-01\n",
      "  3.06629837e-02 2.15930015e-01 8.38858187e-02 3.48066315e-02]\n",
      " [1.25838192e-02 9.14395228e-03 4.65906132e-03 1.76826611e-01\n",
      "  4.24540639e-02 1.49133503e-01 2.62344331e-01 1.31063312e-02\n",
      "  4.39345129e-02 2.88252197e-02 1.68945398e-02 2.40094051e-01]\n",
      " [2.06410810e-01 2.28546783e-02 3.30602261e-03 9.91806854e-03\n",
      "  4.31220367e-04 4.02472317e-02 6.35906279e-01 6.03708485e-03\n",
      "  2.87480245e-04 4.51343954e-02 1.20741697e-02 1.73925534e-02]\n",
      " [8.29745606e-02 5.67514673e-02 1.76125243e-02 1.95694715e-02\n",
      "  2.34833662e-03 4.01174158e-01 2.50489235e-01 1.01369865e-01\n",
      "  1.17416831e-03 1.21330721e-02 9.39334650e-03 4.50097844e-02]\n",
      " [1.76821072e-02 3.07514891e-03 5.41995019e-02 1.42225638e-01\n",
      "  1.03786280e-02 2.06419379e-01 6.16951771e-02 5.68902567e-02\n",
      "  1.85085520e-01 7.57255405e-02 2.57543717e-02 1.60868734e-01]\n",
      " [1.30721495e-01 2.98681147e-02 1.20248254e-02 1.19472459e-01\n",
      "  6.98215654e-03 3.39022487e-01 3.21955010e-02 7.13731572e-02\n",
      "  1.47401085e-02 2.28859577e-02 8.14584941e-02 1.39255241e-01]\n",
      " [4.61323895e-02 7.82104954e-02 6.87694475e-02 9.29084867e-02\n",
      "  6.00793920e-02 8.96899477e-02 2.18538776e-01 1.72191828e-01\n",
      "  2.78940029e-03 2.56410260e-02 5.25694676e-02 9.23720598e-02]]\n"
     ]
    }
   ],
   "source": [
    "tags_matrix = np.zeros((len(tags), len(tags)), dtype='float32')\n",
    "for i, t1 in enumerate(list(tags)):\n",
    "    for j, t2 in enumerate(list(tags)): \n",
    "        tags_matrix[i, j] = t2_given_t1(t2, t1)[0]/t2_given_t1(t2, t1)[1]\n",
    " \n",
    "print(tags_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "048b826e-e345-4fb7-a8c7-e73ec8c78357",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ADJ</th>\n",
       "      <th>NUM</th>\n",
       "      <th>PRON</th>\n",
       "      <th>ADP</th>\n",
       "      <th>CONJ</th>\n",
       "      <th>VERB</th>\n",
       "      <th>NOUN</th>\n",
       "      <th>DET</th>\n",
       "      <th>PRT</th>\n",
       "      <th>X</th>\n",
       "      <th>ADV</th>\n",
       "      <th>.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ADJ</th>\n",
       "      <td>0.063301</td>\n",
       "      <td>0.021748</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>0.080583</td>\n",
       "      <td>0.016893</td>\n",
       "      <td>0.011456</td>\n",
       "      <td>0.696893</td>\n",
       "      <td>0.005243</td>\n",
       "      <td>0.011456</td>\n",
       "      <td>0.020971</td>\n",
       "      <td>0.005243</td>\n",
       "      <td>0.066019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NUM</th>\n",
       "      <td>0.035345</td>\n",
       "      <td>0.184220</td>\n",
       "      <td>0.001428</td>\n",
       "      <td>0.037487</td>\n",
       "      <td>0.014281</td>\n",
       "      <td>0.020707</td>\n",
       "      <td>0.351660</td>\n",
       "      <td>0.003570</td>\n",
       "      <td>0.026062</td>\n",
       "      <td>0.202428</td>\n",
       "      <td>0.003570</td>\n",
       "      <td>0.119243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PRON</th>\n",
       "      <td>0.070615</td>\n",
       "      <td>0.006834</td>\n",
       "      <td>0.006834</td>\n",
       "      <td>0.022323</td>\n",
       "      <td>0.005011</td>\n",
       "      <td>0.484738</td>\n",
       "      <td>0.212756</td>\n",
       "      <td>0.009567</td>\n",
       "      <td>0.014123</td>\n",
       "      <td>0.088383</td>\n",
       "      <td>0.036902</td>\n",
       "      <td>0.041913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADP</th>\n",
       "      <td>0.107062</td>\n",
       "      <td>0.063275</td>\n",
       "      <td>0.069603</td>\n",
       "      <td>0.016958</td>\n",
       "      <td>0.001012</td>\n",
       "      <td>0.008479</td>\n",
       "      <td>0.323589</td>\n",
       "      <td>0.320931</td>\n",
       "      <td>0.001266</td>\n",
       "      <td>0.034548</td>\n",
       "      <td>0.014553</td>\n",
       "      <td>0.038724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CONJ</th>\n",
       "      <td>0.113611</td>\n",
       "      <td>0.040615</td>\n",
       "      <td>0.060373</td>\n",
       "      <td>0.055982</td>\n",
       "      <td>0.000549</td>\n",
       "      <td>0.150384</td>\n",
       "      <td>0.349067</td>\n",
       "      <td>0.123491</td>\n",
       "      <td>0.004391</td>\n",
       "      <td>0.009330</td>\n",
       "      <td>0.057080</td>\n",
       "      <td>0.035126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VERB</th>\n",
       "      <td>0.066390</td>\n",
       "      <td>0.022836</td>\n",
       "      <td>0.035543</td>\n",
       "      <td>0.092357</td>\n",
       "      <td>0.005433</td>\n",
       "      <td>0.167956</td>\n",
       "      <td>0.110589</td>\n",
       "      <td>0.133610</td>\n",
       "      <td>0.030663</td>\n",
       "      <td>0.215930</td>\n",
       "      <td>0.083886</td>\n",
       "      <td>0.034807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NOUN</th>\n",
       "      <td>0.012584</td>\n",
       "      <td>0.009144</td>\n",
       "      <td>0.004659</td>\n",
       "      <td>0.176827</td>\n",
       "      <td>0.042454</td>\n",
       "      <td>0.149134</td>\n",
       "      <td>0.262344</td>\n",
       "      <td>0.013106</td>\n",
       "      <td>0.043935</td>\n",
       "      <td>0.028825</td>\n",
       "      <td>0.016895</td>\n",
       "      <td>0.240094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DET</th>\n",
       "      <td>0.206411</td>\n",
       "      <td>0.022855</td>\n",
       "      <td>0.003306</td>\n",
       "      <td>0.009918</td>\n",
       "      <td>0.000431</td>\n",
       "      <td>0.040247</td>\n",
       "      <td>0.635906</td>\n",
       "      <td>0.006037</td>\n",
       "      <td>0.000287</td>\n",
       "      <td>0.045134</td>\n",
       "      <td>0.012074</td>\n",
       "      <td>0.017393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PRT</th>\n",
       "      <td>0.082975</td>\n",
       "      <td>0.056751</td>\n",
       "      <td>0.017613</td>\n",
       "      <td>0.019569</td>\n",
       "      <td>0.002348</td>\n",
       "      <td>0.401174</td>\n",
       "      <td>0.250489</td>\n",
       "      <td>0.101370</td>\n",
       "      <td>0.001174</td>\n",
       "      <td>0.012133</td>\n",
       "      <td>0.009393</td>\n",
       "      <td>0.045010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X</th>\n",
       "      <td>0.017682</td>\n",
       "      <td>0.003075</td>\n",
       "      <td>0.054200</td>\n",
       "      <td>0.142226</td>\n",
       "      <td>0.010379</td>\n",
       "      <td>0.206419</td>\n",
       "      <td>0.061695</td>\n",
       "      <td>0.056890</td>\n",
       "      <td>0.185086</td>\n",
       "      <td>0.075726</td>\n",
       "      <td>0.025754</td>\n",
       "      <td>0.160869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADV</th>\n",
       "      <td>0.130721</td>\n",
       "      <td>0.029868</td>\n",
       "      <td>0.012025</td>\n",
       "      <td>0.119472</td>\n",
       "      <td>0.006982</td>\n",
       "      <td>0.339022</td>\n",
       "      <td>0.032196</td>\n",
       "      <td>0.071373</td>\n",
       "      <td>0.014740</td>\n",
       "      <td>0.022886</td>\n",
       "      <td>0.081458</td>\n",
       "      <td>0.139255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.</th>\n",
       "      <td>0.046132</td>\n",
       "      <td>0.078210</td>\n",
       "      <td>0.068769</td>\n",
       "      <td>0.092908</td>\n",
       "      <td>0.060079</td>\n",
       "      <td>0.089690</td>\n",
       "      <td>0.218539</td>\n",
       "      <td>0.172192</td>\n",
       "      <td>0.002789</td>\n",
       "      <td>0.025641</td>\n",
       "      <td>0.052569</td>\n",
       "      <td>0.092372</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           ADJ       NUM      PRON       ADP      CONJ      VERB      NOUN  \\\n",
       "ADJ   0.063301  0.021748  0.000194  0.080583  0.016893  0.011456  0.696893   \n",
       "NUM   0.035345  0.184220  0.001428  0.037487  0.014281  0.020707  0.351660   \n",
       "PRON  0.070615  0.006834  0.006834  0.022323  0.005011  0.484738  0.212756   \n",
       "ADP   0.107062  0.063275  0.069603  0.016958  0.001012  0.008479  0.323589   \n",
       "CONJ  0.113611  0.040615  0.060373  0.055982  0.000549  0.150384  0.349067   \n",
       "VERB  0.066390  0.022836  0.035543  0.092357  0.005433  0.167956  0.110589   \n",
       "NOUN  0.012584  0.009144  0.004659  0.176827  0.042454  0.149134  0.262344   \n",
       "DET   0.206411  0.022855  0.003306  0.009918  0.000431  0.040247  0.635906   \n",
       "PRT   0.082975  0.056751  0.017613  0.019569  0.002348  0.401174  0.250489   \n",
       "X     0.017682  0.003075  0.054200  0.142226  0.010379  0.206419  0.061695   \n",
       "ADV   0.130721  0.029868  0.012025  0.119472  0.006982  0.339022  0.032196   \n",
       ".     0.046132  0.078210  0.068769  0.092908  0.060079  0.089690  0.218539   \n",
       "\n",
       "           DET       PRT         X       ADV         .  \n",
       "ADJ   0.005243  0.011456  0.020971  0.005243  0.066019  \n",
       "NUM   0.003570  0.026062  0.202428  0.003570  0.119243  \n",
       "PRON  0.009567  0.014123  0.088383  0.036902  0.041913  \n",
       "ADP   0.320931  0.001266  0.034548  0.014553  0.038724  \n",
       "CONJ  0.123491  0.004391  0.009330  0.057080  0.035126  \n",
       "VERB  0.133610  0.030663  0.215930  0.083886  0.034807  \n",
       "NOUN  0.013106  0.043935  0.028825  0.016895  0.240094  \n",
       "DET   0.006037  0.000287  0.045134  0.012074  0.017393  \n",
       "PRT   0.101370  0.001174  0.012133  0.009393  0.045010  \n",
       "X     0.056890  0.185086  0.075726  0.025754  0.160869  \n",
       "ADV   0.071373  0.014740  0.022886  0.081458  0.139255  \n",
       ".     0.172192  0.002789  0.025641  0.052569  0.092372  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tags_df = pd.DataFrame(tags_matrix, columns = list(tags), index=list(tags))\n",
    "display(tags_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3f34b703-e52a-4c66-b47f-22ee27ff7396",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Viterbi(words, train_bag = train_tagged_words):\n",
    "    state = []\n",
    "    T = list(set([pair[1] for pair in train_bag]))\n",
    "     \n",
    "    for key, word in enumerate(words):\n",
    "        p = [] \n",
    "        for tag in T:\n",
    "            if key == 0:\n",
    "                transition_p = tags_df.loc['.', tag]\n",
    "            else:\n",
    "                transition_p = tags_df.loc[state[-1], tag]\n",
    "                 \n",
    "            # compute emission and  probability states\n",
    "            emission_p = word_given_tag(words[key], tag)[0]/word_given_tag(words[key], tag)[1]\n",
    "            state_probability = emission_p * transition_p    \n",
    "            p.append(state_probability)\n",
    "             \n",
    "        pmax = max(p)\n",
    "        \n",
    "        state_max = T[p.index(pmax)] \n",
    "        state.append(state_max)\n",
    "    return list(zip(words, state))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "482482d5-8e6e-4beb-a4b6-a39be7a31f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "rndom = [random.randint(1,len(test_set)) for x in range(10)]\n",
    "test_run = [test_set[i] for i in rndom]\n",
    "test_run_base = [tup for sent in test_run for tup in sent]\n",
    "test_tagged_words = [tup[0] for sent in test_run for tup in sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "022dfa2a-55f9-4f4a-85da-9bd38b6cfdd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken in seconds:  18.05593180656433\n",
      "Viterbi Algorithm Accuracy:  94.94949494949495\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "tagged_seq = Viterbi(test_tagged_words)\n",
    "end = time.time()\n",
    "difference = end-start\n",
    "print(\"Time taken in seconds: \", difference)\n",
    "\n",
    "check = [i for i, j in zip(tagged_seq, test_run_base) if i == j] \n",
    "accuracy = len(check)/len(tagged_seq)\n",
    "print('Viterbi Algorithm Accuracy: ',accuracy*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b9b73376-4e98-4e0b-b5d4-b515f9efabf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ntest_tagged_words = [tup for sent in test_set for tup in sent]\\ntest_untagged_words = [tup[0] for sent in test_set for tup in sent]\\ntest_untagged_words\\n\\nstart = time.time()\\ntagged_seq = Viterbi(test_untagged_words)\\nend = time.time()\\ndifference = end-start\\n \\nprint(\"Time taken in seconds: \", difference)\\n\\ncheck = [i for i, j in zip(test_tagged_words, test_untagged_words) if i == j] \\n \\naccuracy = len(check)/len(tagged_seq)\\nprint(\\'Viterbi Algorithm Accuracy: \\',accuracy*100)\\n'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Takes too long to run\n",
    "'''\n",
    "test_tagged_words = [tup for sent in test_set for tup in sent]\n",
    "test_untagged_words = [tup[0] for sent in test_set for tup in sent]\n",
    "test_untagged_words\n",
    "\n",
    "start = time.time()\n",
    "tagged_seq = Viterbi(test_untagged_words)\n",
    "end = time.time()\n",
    "difference = end-start\n",
    " \n",
    "print(\"Time taken in seconds: \", difference)\n",
    "\n",
    "check = [i for i, j in zip(test_tagged_words, test_untagged_words) if i == j] \n",
    " \n",
    "accuracy = len(check)/len(tagged_seq)\n",
    "print('Viterbi Algorithm Accuracy: ',accuracy*100)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ef65a3a8-6791-4947-87c4-cf3e90921b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "patterns = [\n",
    "    (r'.*ing$', 'VERB'),              # gerund\n",
    "    (r'.*ed$', 'VERB'),               # past tense \n",
    "    (r'.*es$', 'VERB'),               # verb    \n",
    "    (r'.*\\'s$', 'NOUN'),              # possessive nouns\n",
    "    (r'.*s$', 'NOUN'),                # plural nouns\n",
    "    (r'\\*T?\\*?-[0-9]+$', 'X'),        # X\n",
    "    (r'^-?[0-9]+(.[0-9]+)?$', 'NUM'), # cardinal numbers\n",
    "    (r'.*', 'NOUN')                   # nouns\n",
    "]\n",
    "\n",
    "rule_based_tagger = nltk.RegexpTagger(patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4520ee91-2841-4fe1-b9cd-12f871bd6d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Viterbi_rule_based(words, train_bag = train_tagged_words):\n",
    "    state = []\n",
    "    T = list(set([pair[1] for pair in train_bag]))\n",
    "     \n",
    "    for key, word in enumerate(words):\n",
    "        p = [] \n",
    "        for tag in T:\n",
    "            if key == 0:\n",
    "                transition_p = tags_df.loc['.', tag]\n",
    "            else:\n",
    "                transition_p = tags_df.loc[state[-1], tag]\n",
    "                 \n",
    "            # compute emission and  probability states\n",
    "            emission_p = word_given_tag(words[key], tag)[0]/word_given_tag(words[key], tag)[1]\n",
    "            state_probability = emission_p * transition_p    \n",
    "            p.append(state_probability)\n",
    "             \n",
    "        pmax = max(p)\n",
    "        state_max = rule_based_tagger.tag([word])[0][1]       \n",
    "        \n",
    "         \n",
    "        if(pmax==0):\n",
    "            state_max = rule_based_tagger.tag([word])[0][1]\n",
    "        else:\n",
    "            if state_max != 'X':\n",
    "                state_max = T[p.index(pmax)]                \n",
    "             \n",
    "         \n",
    "        state.append(state_max)\n",
    "    return list(zip(words, state))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "82063bf5-8249-488f-ab1c-c86a831689e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken in seconds:  19.284300088882446\n",
      "Viterbi Algorithm Accuracy:  98.48484848484848\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "tagged_seq = Viterbi_rule_based(test_tagged_words)\n",
    "end = time.time()\n",
    "difference = end-start\n",
    " \n",
    "print(\"Time taken in seconds: \", difference)\n",
    "\n",
    "check = [i for i, j in zip(tagged_seq, test_run_base) if i == j] \n",
    " \n",
    "accuracy = len(check)/len(tagged_seq)\n",
    "print('Viterbi Algorithm Accuracy: ',accuracy*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "171412d4-a882-445d-96e9-4eaf2157fe74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Will', 'NOUN'), ('can', 'VERB'), ('see', 'VERB'), ('Marry', 'NOUN')]\n",
      "[('Will', 'ADJ'), ('can', 'VERB'), ('see', 'VERB'), ('Marry', 'ADJ')]\n"
     ]
    }
   ],
   "source": [
    "test_sent=\"Will can see Marry\"\n",
    "pred_tags_rule=Viterbi_rule_based(test_sent.split())\n",
    "pred_tags_withoutRules= Viterbi(test_sent.split())\n",
    "print(pred_tags_rule)\n",
    "print(pred_tags_withoutRules)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a732b74-fbc2-4f32-8898-0d5cdda44f65",
   "metadata": {},
   "source": [
    "## Exercise 2:\n",
    "\n",
    "- Find a new text dataset\n",
    "- Convert it into csv format\n",
    "- Redo the same exercise\n",
    "\n",
    "\n",
    "### a & b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c3037b7b-26e0-48a3-9bc3-e1a97fd55459",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk.corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f83c81fc-8752-4d89-96a5-233230036ef3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to\n",
      "[nltk_data]     /Users/danielmehta/nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n",
      "[nltk_data] Downloading package universal_tagset to\n",
      "[nltk_data]     /Users/danielmehta/nltk_data...\n",
      "[nltk_data]   Package universal_tagset is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('brown')\n",
    "nltk.download('universal_tagset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a3e1664f-dbdc-4c93-930f-f0e363e3c62d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('The', 'DET'), ('Fulton', 'NOUN'), ('County', 'NOUN'), ('Grand', 'ADJ'), ('Jury', 'NOUN'), ('said', 'VERB'), ('Friday', 'NOUN'), ('an', 'DET'), ('investigation', 'NOUN'), ('of', 'ADP'), (\"Atlanta's\", 'NOUN'), ('recent', 'ADJ'), ('primary', 'NOUN'), ('election', 'NOUN'), ('produced', 'VERB'), ('``', '.'), ('no', 'DET'), ('evidence', 'NOUN'), (\"''\", '.'), ('that', 'ADP'), ('any', 'DET'), ('irregularities', 'NOUN'), ('took', 'VERB'), ('place', 'NOUN'), ('.', '.')], [('The', 'DET'), ('jury', 'NOUN'), ('further', 'ADV'), ('said', 'VERB'), ('in', 'ADP'), ('term-end', 'NOUN'), ('presentments', 'NOUN'), ('that', 'ADP'), ('the', 'DET'), ('City', 'NOUN'), ('Executive', 'ADJ'), ('Committee', 'NOUN'), (',', '.'), ('which', 'DET'), ('had', 'VERB'), ('over-all', 'ADJ'), ('charge', 'NOUN'), ('of', 'ADP'), ('the', 'DET'), ('election', 'NOUN'), (',', '.'), ('``', '.'), ('deserves', 'VERB'), ('the', 'DET'), ('praise', 'NOUN'), ('and', 'CONJ'), ('thanks', 'NOUN'), ('of', 'ADP'), ('the', 'DET'), ('City', 'NOUN'), ('of', 'ADP'), ('Atlanta', 'NOUN'), (\"''\", '.'), ('for', 'ADP'), ('the', 'DET'), ('manner', 'NOUN'), ('in', 'ADP'), ('which', 'DET'), ('the', 'DET'), ('election', 'NOUN'), ('was', 'VERB'), ('conducted', 'VERB'), ('.', '.')], ...]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.corpus.brown.tagged_sents(tagset='universal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3db7b379-d438-4ec4-8782-fd28d7e488b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "brown_tagged = nltk.corpus.brown.tagged_sents(tagset='universal')[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1eea23c6-8f99-46ec-bff6-2e015fe91bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "flattened = [(word, tag) for sent in brown_tagged for (word, tag) in sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c183eef7-8847-47e8-94e5-e35737887673",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(flattened, columns=['Word', 'Tag'])\n",
    "df.to_csv('brown_pos.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83652ab2-2ad2-432b-bb9f-94c953105644",
   "metadata": {},
   "source": [
    "### c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3fb43ce5-e632-4892-9d6a-c8c8f1a96944",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split training and validation 80/20\n",
    "train_sents, test_sents = train_test_split(brown_tagged, train_size=0.8, random_state=5501)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "24eecb35-83f5-4a33-9541-32836412b443",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tagged_words = [tup for sent in train_sents for tup in sent]\n",
    "test_tagged_words = [tup for sent in test_sents for tup in sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e1ffa9f9-415c-45c1-b3ec-842e7806c1bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 9492\n",
      "Test: 2219\n"
     ]
    }
   ],
   "source": [
    "print(\"Train:\", len(train_tagged_words))\n",
    "print(\"Test:\", len(test_tagged_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b657b71d-14c7-47b0-95d7-274700c60f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_given_tag(word, tag, train_bag = train_tagged_words):\n",
    "    tag_list = [pair for pair in train_bag if pair[1]==tag]\n",
    "    count_tag = len(tag_list)\n",
    "    w_given_tag_list = [pair[0] for pair in tag_list if pair[0]==word]\n",
    "    count_w_given_tag = len(w_given_tag_list)\n",
    "     \n",
    "    return (count_w_given_tag, count_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f85bfbe2-6f1d-45e7-ad83-4e15ca635fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def t2_given_t1(t2, t1, train_bag = train_tagged_words):\n",
    "    tags = [pair[1] for pair in train_bag]\n",
    "    count_t1 = len([t for t in tags if t==t1])\n",
    "    count_t2_t1 = 0\n",
    "    for index in range(len(tags)-1):\n",
    "        if tags[index]==t1 and tags[index+1]== t2:\n",
    "            count_t2_t1 += 1\n",
    "    return (count_t2_t1, count_t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "594b094d-5605-4c9f-81ce-90b6e523ed58",
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = sorted(list({tag for _, tag in train_tagged_words}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2838e198-dd4d-48bb-ba37-ba8ca32b5fcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.10965795 0.04426559 0.09959759 0.04627766 0.05633803 0.18812877\n",
      "  0.23138833 0.02615694 0.07645875 0.02012073 0.10060363 0.        ]\n",
      " [0.05322581 0.06129032 0.0483871  0.00322581 0.02741935 0.00322581\n",
      "  0.75       0.01129032 0.         0.02580645 0.01451613 0.0016129 ]\n",
      " [0.01071723 0.08244023 0.02555647 0.00741962 0.0016488  0.4286892\n",
      "  0.30008245 0.05441055 0.03050289 0.00824402 0.05028854 0.        ]\n",
      " [0.08       0.12       0.15272728 0.06909091 0.01454545 0.06909091\n",
      "  0.02181818 0.00727273 0.04       0.04       0.38545454 0.        ]\n",
      " [0.00921659 0.14285715 0.05990783 0.05529954 0.         0.16129032\n",
      "  0.33179724 0.01382488 0.04147466 0.02304148 0.16129032 0.        ]\n",
      " [0.01358696 0.21014492 0.01086957 0.00905797 0.         0.00543478\n",
      "  0.6512681  0.02173913 0.00724638 0.00271739 0.06793478 0.        ]\n",
      " [0.22210708 0.017962   0.23039724 0.01692573 0.03937824 0.01761658\n",
      "  0.25423142 0.00725389 0.01139896 0.02901554 0.1537133  0.        ]\n",
      " [0.14857143 0.10285714 0.14857143 0.00571429 0.04       0.02857143\n",
      "  0.41714287 0.06285714 0.01714286 0.00571429 0.02285714 0.        ]\n",
      " [0.06493507 0.004329   0.05194805 0.04761905 0.00865801 0.02164502\n",
      "  0.         0.         0.01298701 0.01298701 0.7748918  0.        ]\n",
      " [0.03846154 0.00854701 0.06837607 0.02136752 0.0042735  0.04273504\n",
      "  0.03846154 0.         0.         0.0042735  0.77350426 0.        ]\n",
      " [0.06984334 0.04503917 0.17297651 0.07245431 0.00913838 0.17167102\n",
      "  0.14360313 0.00979112 0.03328982 0.05221932 0.21997389 0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.5        0.         0.         0.         0.         0.5       ]]\n"
     ]
    }
   ],
   "source": [
    "tags_matrix = np.zeros((len(tags), len(tags)), dtype='float32')\n",
    "for i, t1 in enumerate(list(tags)):\n",
    "    for j, t2 in enumerate(list(tags)): \n",
    "        tags_matrix[i, j] = t2_given_t1(t2, t1)[0]/t2_given_t1(t2, t1)[1]\n",
    " \n",
    "print(tags_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cbecf7fd-2b8b-4264-bdfa-06752ab0c144",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             .       ADJ       ADP       ADV      CONJ       DET      NOUN  \\\n",
      ".     0.109658  0.044266  0.099598  0.046278  0.056338  0.188129  0.231388   \n",
      "ADJ   0.053226  0.061290  0.048387  0.003226  0.027419  0.003226  0.750000   \n",
      "ADP   0.010717  0.082440  0.025556  0.007420  0.001649  0.428689  0.300082   \n",
      "ADV   0.080000  0.120000  0.152727  0.069091  0.014545  0.069091  0.021818   \n",
      "CONJ  0.009217  0.142857  0.059908  0.055300  0.000000  0.161290  0.331797   \n",
      "DET   0.013587  0.210145  0.010870  0.009058  0.000000  0.005435  0.651268   \n",
      "NOUN  0.222107  0.017962  0.230397  0.016926  0.039378  0.017617  0.254231   \n",
      "NUM   0.148571  0.102857  0.148571  0.005714  0.040000  0.028571  0.417143   \n",
      "PRON  0.064935  0.004329  0.051948  0.047619  0.008658  0.021645  0.000000   \n",
      "PRT   0.038462  0.008547  0.068376  0.021368  0.004274  0.042735  0.038462   \n",
      "VERB  0.069843  0.045039  0.172977  0.072454  0.009138  0.171671  0.143603   \n",
      "X     0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.500000   \n",
      "\n",
      "           NUM      PRON       PRT      VERB         X  \n",
      ".     0.026157  0.076459  0.020121  0.100604  0.000000  \n",
      "ADJ   0.011290  0.000000  0.025806  0.014516  0.001613  \n",
      "ADP   0.054411  0.030503  0.008244  0.050289  0.000000  \n",
      "ADV   0.007273  0.040000  0.040000  0.385455  0.000000  \n",
      "CONJ  0.013825  0.041475  0.023041  0.161290  0.000000  \n",
      "DET   0.021739  0.007246  0.002717  0.067935  0.000000  \n",
      "NOUN  0.007254  0.011399  0.029016  0.153713  0.000000  \n",
      "NUM   0.062857  0.017143  0.005714  0.022857  0.000000  \n",
      "PRON  0.000000  0.012987  0.012987  0.774892  0.000000  \n",
      "PRT   0.000000  0.000000  0.004274  0.773504  0.000000  \n",
      "VERB  0.009791  0.033290  0.052219  0.219974  0.000000  \n",
      "X     0.000000  0.000000  0.000000  0.000000  0.500000  \n"
     ]
    }
   ],
   "source": [
    "tags_matrix = np.zeros((len(tags), len(tags)), dtype='float32')\n",
    "\n",
    "for i, t1 in enumerate(tags):\n",
    "    for j, t2 in enumerate(tags):\n",
    "        count_t2_t1, count_t1 = t2_given_t1(t2, t1)\n",
    "        if count_t1 == 0:\n",
    "            tags_matrix[i, j] = 0.0\n",
    "        else:\n",
    "            tags_matrix[i, j] = count_t2_t1 / count_t1\n",
    "\n",
    "tags_df = pd.DataFrame(tags_matrix, columns=tags, index=tags)\n",
    "print(tags_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "adb2ee22-9c8a-4f72-8b72-3293af841299",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Viterbi(words, train_bag=train_tagged_words):\n",
    "    state = []\n",
    "    T = list(set([tag for _, tag in train_bag]))\n",
    "\n",
    "    for i, word in enumerate(words):\n",
    "        p = []\n",
    "        for tag in T:\n",
    "            if i == 0:\n",
    "                trans_p = tags_df.loc['.',tag] if '.' in tags_df.index else 1e-6\n",
    "            else:\n",
    "                trans_p = tags_df.loc[state[-1],tag] if state[-1] in tags_df.index else 1e-6\n",
    "\n",
    "            # Emission\n",
    "            emission_count, tag_count = word_given_tag(word, tag)\n",
    "            emission_p = emission_count /tag_count if tag_count > 0 else 1e-6\n",
    "\n",
    "            # Combined prob\n",
    "            state_p = emission_p * trans_p\n",
    "            p.append(state_p)\n",
    "\n",
    "        max_p = max(p)\n",
    "        max_state = T[p.index(max_p)]\n",
    "        state.append(max_state)\n",
    "\n",
    "    return list(zip(words, state))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "57941293-7861-488b-a20c-44b6b7614399",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken in seconds: 12.2067\n",
      "Viterbi Algorithm Accuracy: 82.47 %\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "test_words = [word for word, _ in test_tagged_words]\n",
    "tagged_seq = Viterbi(test_words)\n",
    "\n",
    "end = time.time()\n",
    "difference = end - start\n",
    "\n",
    "print(\"Time taken in seconds:\", round(difference, 4))\n",
    "correct = [pred for pred, actual in zip(tagged_seq, test_tagged_words) if pred == actual]\n",
    "accuracy = len(correct) / len(tagged_seq)\n",
    "\n",
    "print(\"Viterbi Algorithm Accuracy:\", round(accuracy * 100, 2), \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0206071-526d-4ea2-bdaf-4d78df049eeb",
   "metadata": {},
   "source": [
    "## Exercise 3: [Markov Chains in Python with Model Examples](https://www.datacamp.com/tutorial/markov-chains-python-tutorial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0318852e-1355-4eb7-8af6-a0a4241fd74b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random as rm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ae7941aa-56d8-4caf-87d2-552db2a7ff39",
   "metadata": {},
   "outputs": [],
   "source": [
    "states = [\"Sleep\",\"Icecream\",\"Run\"]\n",
    "\n",
    "transitionName = [[\"SS\",\"SR\",\"SI\"],[\"RS\",\"RR\",\"RI\"],[\"IS\",\"IR\",\"II\"]]\n",
    "\n",
    "transitionMatrix = [[0.2,0.6,0.2],[0.1,0.6,0.3],[0.2,0.7,0.1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d5e77bb7-8841-4dc9-b72f-27c0e7dc5a26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All is gonna be okay, you should move on!! ;)\n"
     ]
    }
   ],
   "source": [
    "if sum(transitionMatrix[0])+sum(transitionMatrix[1])+sum(transitionMatrix[1]) != 3:\n",
    "    print(\"Somewhere, something went wrong. Transition matrix, perhaps?\")\n",
    "else: print(\"All is gonna be okay, you should move on!! ;)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1e259800-58ed-4fc9-a474-b27d4ad91a88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start state: Sleep\n",
      "Possible states: ['Sleep', 'Sleep', 'Run']\n",
      "End state after 2 days: Run\n",
      "Probability of the possible sequence of states: 0.12\n"
     ]
    }
   ],
   "source": [
    "# A function that implements the Markov model to forecast the state/mood.\n",
    "def activity_forecast(days):\n",
    "    # Choose the starting state\n",
    "    activityToday = \"Sleep\"\n",
    "    print(\"Start state: \" + activityToday)\n",
    "    # Shall store the sequence of states taken. So, this only has the starting state for now.\n",
    "    activityList = [activityToday]\n",
    "    i = 0\n",
    "    # To calculate the probability of the activityList\n",
    "    prob = 1\n",
    "    while i != days:\n",
    "        if activityToday == \"Sleep\":\n",
    "            change = np.random.choice(transitionName[0],replace=True,p=transitionMatrix[0])\n",
    "            if change == \"SS\":\n",
    "                prob = prob * 0.2\n",
    "                activityList.append(\"Sleep\")\n",
    "                pass\n",
    "            elif change == \"SR\":\n",
    "                prob = prob * 0.6\n",
    "                activityToday = \"Run\"\n",
    "                activityList.append(\"Run\")\n",
    "            else:\n",
    "                prob = prob * 0.2\n",
    "                activityToday = \"Icecream\"\n",
    "                activityList.append(\"Icecream\")\n",
    "        elif activityToday == \"Run\":\n",
    "            change = np.random.choice(transitionName[1],replace=True,p=transitionMatrix[1])\n",
    "            if change == \"RR\":\n",
    "                prob = prob * 0.5\n",
    "                activityList.append(\"Run\")\n",
    "                pass\n",
    "            elif change == \"RS\":\n",
    "                prob = prob * 0.2\n",
    "                activityToday = \"Sleep\"\n",
    "                activityList.append(\"Sleep\")\n",
    "            else:\n",
    "                prob = prob * 0.3\n",
    "                activityToday = \"Icecream\"\n",
    "                activityList.append(\"Icecream\")\n",
    "        elif activityToday == \"Icecream\":\n",
    "            change = np.random.choice(transitionName[2],replace=True,p=transitionMatrix[2])\n",
    "            if change == \"II\":\n",
    "                prob = prob * 0.1\n",
    "                activityList.append(\"Icecream\")\n",
    "                pass\n",
    "            elif change == \"IS\":\n",
    "                prob = prob * 0.2\n",
    "                activityToday = \"Sleep\"\n",
    "                activityList.append(\"Sleep\")\n",
    "            else:\n",
    "                prob = prob * 0.7\n",
    "                activityToday = \"Run\"\n",
    "                activityList.append(\"Run\")\n",
    "        i += 1  \n",
    "    print(\"Possible states: \" + str(activityList))\n",
    "    print(\"End state after \"+ str(days) + \" days: \" + activityToday)\n",
    "    print(\"Probability of the possible sequence of states: \" + str(prob))\n",
    "\n",
    "# Function that forecasts the possible state for the next 2 days\n",
    "activity_forecast(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2966ffe9-8365-48c9-81f3-6602b444bed3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The probability of starting at state:'Sleep' and ending at state:'Run'= 61.95%\n"
     ]
    }
   ],
   "source": [
    "def activity_forecast(days):\n",
    "    # Choose the starting state\n",
    "    activityToday = \"Sleep\"\n",
    "    activityList = [activityToday]\n",
    "    i = 0\n",
    "    prob = 1\n",
    "    while i != days:\n",
    "        if activityToday == \"Sleep\":\n",
    "            change = np.random.choice(transitionName[0],replace=True,p=transitionMatrix[0])\n",
    "            if change == \"SS\":\n",
    "                prob = prob * 0.2\n",
    "                activityList.append(\"Sleep\")\n",
    "                pass\n",
    "            elif change == \"SR\":\n",
    "                prob = prob * 0.6\n",
    "                activityToday = \"Run\"\n",
    "                activityList.append(\"Run\")\n",
    "            else:\n",
    "                prob = prob * 0.2\n",
    "                activityToday = \"Icecream\"\n",
    "                activityList.append(\"Icecream\")\n",
    "        elif activityToday == \"Run\":\n",
    "            change = np.random.choice(transitionName[1],replace=True,p=transitionMatrix[1])\n",
    "            if change == \"RR\":\n",
    "                prob = prob * 0.5\n",
    "                activityList.append(\"Run\")\n",
    "                pass\n",
    "            elif change == \"RS\":\n",
    "                prob = prob * 0.2\n",
    "                activityToday = \"Sleep\"\n",
    "                activityList.append(\"Sleep\")\n",
    "            else:\n",
    "                prob = prob * 0.3\n",
    "                activityToday = \"Icecream\"\n",
    "                activityList.append(\"Icecream\")\n",
    "        elif activityToday == \"Icecream\":\n",
    "            change = np.random.choice(transitionName[2],replace=True,p=transitionMatrix[2])\n",
    "            if change == \"II\":\n",
    "                prob = prob * 0.1\n",
    "                activityList.append(\"Icecream\")\n",
    "                pass\n",
    "            elif change == \"IS\":\n",
    "                prob = prob * 0.2\n",
    "                activityToday = \"Sleep\"\n",
    "                activityList.append(\"Sleep\")\n",
    "            else:\n",
    "                prob = prob * 0.7\n",
    "                activityToday = \"Run\"\n",
    "                activityList.append(\"Run\")\n",
    "        i += 1    \n",
    "    return activityList\n",
    "\n",
    "# To save every activityList\n",
    "list_activity = []\n",
    "count = 0\n",
    "\n",
    "# `Range` starts from the first count up until but excluding the last count\n",
    "for iterations in range(1,10000):\n",
    "        list_activity.append(activity_forecast(2))\n",
    "\n",
    "# Check out all the `activityList` we collected    \n",
    "#print(list_activity)\n",
    "\n",
    "# Iterate through the list to get a count of all activities ending in state:'Run'\n",
    "for smaller_list in list_activity:\n",
    "    if(smaller_list[2] == \"Run\"):\n",
    "        count += 1\n",
    "\n",
    "# Calculate the probability of starting from state:'Sleep' and ending at state:'Run'\n",
    "percentage = (count/10000) * 100\n",
    "print(\"The probability of starting at state:'Sleep' and ending at state:'Run'= \" + str(percentage) + \"%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad4c5c1-4fb2-45c1-afb6-9f7aff873d63",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (moflow)",
   "language": "python",
   "name": "moflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
