{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2958f5c-89d8-449c-b0b8-c85abdcc6a30",
   "metadata": {},
   "source": [
    "# Exercise 2\n",
    "## Neural machine translation with attention\n",
    "### By: Daniel Mehta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "510b1a81-38b7-44b4-af2c-01d7245cbebb",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Imports and Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c8752830-c3d1-4b09-b820-bfdf8b5496f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import random\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e73e25d9-56aa-4021-8aa3-0ba43834733c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up seed\n",
    "SEED = 5501\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "77bed902-4410-45db-ba9b-c42d046bbbae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# setting device\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76489bd6-9d9d-4bf3-938b-13096d5fee09",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Dataset Path Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc156b12-e9ba-4e8f-a908-205009784407",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting path to dataset\n",
    "data_dir = Path(\"spa-eng\")\n",
    "data_path = data_dir / \"spa.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "780ef227-87f6-4cbc-9ced-e546cb7ce148",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset located at: spa-eng\\spa.txt\n"
     ]
    }
   ],
   "source": [
    "if not data_path.exists():\n",
    "    raise FileNotFoundError(f\"Dataset not found at {data_path}\")\n",
    "print(f\"Dataset located at: {data_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af606eb-07c1-447d-b2c8-1df3b1275a22",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Data Exploration and Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "03d6e9ba-1918-4402-9589-c542bafa350a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading the file and split into lines\n",
    "with open(data_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    lines = f.read().strip().split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "52ca9c00-a792-497c-8576-d190c043702d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total sentence pairs in file: 142511\n",
      "Sample lines:\n",
      "Go.\tVe.\tCC-BY 2.0 (France) Attribution: tatoeba.org #2877272 (CM) & #4986655 (cueyayotl)\n",
      "Go.\tVete.\tCC-BY 2.0 (France) Attribution: tatoeba.org #2877272 (CM) & #4986656 (cueyayotl)\n",
      "Go.\tVaya.\tCC-BY 2.0 (France) Attribution: tatoeba.org #2877272 (CM) & #4986657 (cueyayotl)\n",
      "Go.\tVÃ¡yase.\tCC-BY 2.0 (France) Attribution: tatoeba.org #2877272 (CM) & #6586271 (arh)\n",
      "Hi.\tHola.\tCC-BY 2.0 (France) Attribution: tatoeba.org #538123 (CM) & #431975 (Leono)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total sentence pairs in file: {len(lines)}\")\n",
    "print(\"Sample lines:\")\n",
    "for i in range(5):\n",
    "    print(lines[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "15a78ea1-9da5-48cb-b27c-b5922ac18de2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Example pair:\n",
      "EN: Go.\n",
      "ES: Ve.\n"
     ]
    }
   ],
   "source": [
    "#Separating into English and Spanish\n",
    "pairs = [line.split(\"\\t\") for line in lines]\n",
    "english_sentences = [pair[0] for pair in pairs] #English (target)\n",
    "spanish_sentences = [pair[1] for pair in pairs] #Spanish (source)\n",
    "\n",
    "print(\"\\nExample pair:\")\n",
    "print(\"EN:\", english_sentences[0])\n",
    "print(\"ES:\", spanish_sentences[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78cd0046-cdd1-4b98-8de2-ec3bdc5a325d",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Tokenization & vocab building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "03d1b6e5-4478-47b9-8f8a-822b6bb378b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  start and end tokens to the English targets\n",
    "START_TOKEN=\"<start>\"\n",
    "END_TOKEN=\"<end>\"\n",
    "\n",
    "english_sentences = [f\"{START_TOKEN} {s} {END_TOKEN}\" for s in english_sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6920bffb-3949-4bd0-bda1-a45450c157f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Basic tokenization\n",
    "#lowercase, split on spaces, strip punctuation\n",
    "def tokenize(text):\n",
    "    return text.lower().strip().split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1b14735e-2123-445b-b2aa-fc9b4d60d574",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokenize all the sentences\n",
    "tokenized_es = [tokenize(s) for s in spanish_sentences]\n",
    "tokenized_en = [tokenize(s) for s in english_sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "37b8005c-b417-40b6-a883-415fc276e590",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build vocabularies\n",
    "def build_vocab(tokenized_sents,min_freq=1):\n",
    "    counter = Counter(token for sent in tokenized_sents for token in sent)\n",
    "    vocab = {token: idx+2 for idx, (token, freq) in enumerate(counter.items()) if freq >= min_freq}\n",
    "    vocab[\"<pad>\"] =0\n",
    "    vocab[\"<unk>\"] =1\n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a4be4cd2-8bf2-4384-927b-28a7b321d3f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_vocab = build_vocab(tokenized_es)\n",
    "tgt_vocab = build_vocab(tokenized_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "87a91776-70ad-400f-af7f-120512f34068",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reverse look up for decoding \n",
    "src_idx2word = {idx: word for word,idx in src_vocab.items()}\n",
    "tgt_idx2word = {idx: word for word,idx in tgt_vocab.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9e2988be-01e3-4e6c-93b5-96429e0e19d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source vocab size (ES): 46045\n",
      "Target vocab size (EN): 25767\n"
     ]
    }
   ],
   "source": [
    "print(f\"Source vocab size (ES): {len(src_vocab)}\")\n",
    "print(f\"Target vocab size (EN): {len(tgt_vocab)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "940d504f-af82-49ae-abd6-80da48c7f706",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "##  Convert sentences to index tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "61c60cd8-66c1-48b6-b298-e180c4006ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Numericalize tokenized sentences\n",
    "def numericalize(tokenized_sents,vocab):\n",
    "    return [torch.tensor([vocab.get(tok,vocab[\"<unk>\"]) for tok in sent],dtype=torch.long) \n",
    "            for sent in tokenized_sents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "04b77b5e-0da4-40bc-9b8d-3ea4ae4d1e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_tensors =numericalize(tokenized_es, src_vocab)\n",
    "tgt_input_tensors = numericalize([sent[:-1] for sent in tokenized_en], tgt_vocab)# without <end>\n",
    "tgt_target_tensors = numericalize([sent[1:] for sent in tokenized_en], tgt_vocab)# without <start>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "989f45f6-1711-41e3-830f-a84c906ceea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pad the sequences\n",
    "src_tensors = pad_sequence(src_tensors,batch_first=True, padding_value=src_vocab[\"<pad>\"])\n",
    "tgt_input_tensors = pad_sequence(tgt_input_tensors,batch_first=True, padding_value=tgt_vocab[\"<pad>\"])\n",
    "tgt_target_tensors = pad_sequence(tgt_target_tensors,batch_first=True, padding_value=tgt_vocab[\"<pad>\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "856ecd83-dfda-46ef-951f-8ff32a7b3bf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example ES tensor: tensor([2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "Example EN input tensor: tensor([2, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "Example EN target tensor: tensor([3, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "print(f\"Example ES tensor: {src_tensors[0]}\")\n",
    "print(f\"Example EN input tensor: {tgt_input_tensors[0]}\")\n",
    "print(f\"Example EN target tensor: {tgt_target_tensors[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "315c9077-f0ea-403a-ae9f-59ba4cbe48b7",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Dataloader Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a67358cc-2ea9-4712-a6e8-79096984b013",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combineing into dataset\n",
    "dataset=list(zip(src_tensors,tgt_input_tensors,tgt_target_tensors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "26bba207-e31e-40dc-a4d5-a4b1ea3a976d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train batches: 1782, Val batches: 446\n"
     ]
    }
   ],
   "source": [
    "# Train/validation split (80/20)\n",
    "split_idx=int(len(dataset)*0.8)\n",
    "train_data=dataset[:split_idx]\n",
    "val_data=dataset[split_idx:]\n",
    "\n",
    "BATCH_SIZE =64\n",
    "\n",
    "train_loader = DataLoader(train_data,batch_size=BATCH_SIZE,shuffle=True)\n",
    "val_loader = DataLoader(val_data,batch_size=BATCH_SIZE)\n",
    "\n",
    "print(f\"Train batches: {len(train_loader)}, Val batches: {len(val_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b68f4c4-aaff-4ca9-b405-beb9b5cf691c",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148cbeff-0d97-49e6-b3cc-ffb3878f4d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_vocab_size, embed_dim, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.embedding =nn.Embedding(input_vocab_size,embed_dim)\n",
    "        self.gru =nn.GRU(embed_dim, hidden_dim, batch_first=True,bidirectional=True)\n",
    "        self.fc =nn.Linear(hidden_dim*2, hidden_dim)# project bi GRU utput to hiddendim\n",
    "\n",
    "    def forward(self, src_idxs):\n",
    "        # src_idxs:(batch,src_len)\n",
    "        embedded = self.embedding(src_idxs) #(batch, rc_len,embed_dim)\n",
    "        outputs, hidden = self.gru(embedded) # outputs:(batch,src_len,hidden_dim*2)\n",
    "        \n",
    "        # Mergeing the bidirectional hidden states\n",
    "        hidden=torch.tanh(self.fc(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim=1))) # (batch, hidden_dim)\n",
    "        hidden=hidden.unsqueeze(0) # (1, batch, hidden_dim)\n",
    "        \n",
    "        return outputs, hidden # outputs for attention, hidden for decoder init\n",
    "\n",
    "\n",
    "class LuongAttention(nn.Module):\n",
    "    def __init__(self, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.attn =nn.Linear(hidden_dim, hidden_dim)\n",
    "\n",
    "    def forward(self, decoder_hidden, encoder_outputs):\n",
    "        # decoder_hidden:(1, batch, hidden_dim)\n",
    "        # encoder_outputs:(batch, src_len, hidden_dim)\n",
    "        \n",
    "        # Repeat decoder hidden state across src_len\n",
    "        decoder_hidden =decoder_hidden.permute(1,0,2) #(batch,1,hidden_dim)\n",
    "        \n",
    "        # score: batch matrix multiply\n",
    "        scores = torch.bmm(self.attn(encoder_outputs), decoder_hidden.transpose(1, 2))# (batch, src_len, 1)\n",
    "        attn_weights = torch.softmax(scores,dim=1) # (batch, src_len, 1)\n",
    "        \n",
    "        #Context vector\n",
    "        context = torch.bmm(attn_weights.transpose(1,2), encoder_outputs)#(batch, 1, hidden_dim)\n",
    "        \n",
    "        return context,attn_weights\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self,output_vocab_size, embed_dim,hidden_dim):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(output_vocab_size, embed_dim)\n",
    "        self.gru =nn.GRU(embed_dim+hidden_dim, hidden_dim, batch_first=True)\n",
    "        self.fc_out = nn.Linear(hidden_dim *2,output_vocab_size)\n",
    "        self.attention = LuongAttention(hidden_dim)\n",
    "\n",
    "    def forward(self, tgt_input_idxs, hidden, encoder_outputs):\n",
    "        # tgt_input_idxs: (batch, tgt_len)\n",
    "        embedded = self.embedding(tgt_input_idxs) # (batch, tgt_len, embed_dim)\n",
    "        \n",
    "        outputs = []\n",
    "        for t in range(embedded.size(1)):# step through target sequence\n",
    "            input_t = embedded[:, t, :].unsqueeze(1) #(batch, 1,embed_dim)\n",
    "            \n",
    "            # Attention context\n",
    "            context, attn_weights =self.attention(hidden,encoder_outputs)\n",
    "            \n",
    "            # Combineing the context with current input\n",
    "            rnn_input = torch.cat((input_t, context),dim= 2)# (batch, 1, embed_dim+hidden_dim)\n",
    "            \n",
    "            output,hidden = self.gru(rnn_input, hidden) # output: (batch, 1, hidden_dim)\n",
    "            \n",
    "            #The Final output layer\n",
    "            output_combined = torch.cat((output, context),dim= 2)# (batch, 1, hidden_dim*2)\n",
    "            prediction = self.fc_out(output_combined) # (batch,1, output_vocab_size)\n",
    "            \n",
    "            outputs.append(prediction)\n",
    "        \n",
    "        outputs = torch.cat(outputs, dim=1) #(batch,tgt_len,output_vocab_size)\n",
    "        return outputs\n",
    "\n",
    "\n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, device):\n",
    "        super().__init__()\n",
    "        self.encoder=encoder\n",
    "        self.decoder=decoder\n",
    "        self.device=device\n",
    "\n",
    "    def forward(self, src_idxs, tgt_input_idxs):\n",
    "        encoder_outputs,hidden=self.encoder(src_idxs)\n",
    "        outputs =self.decoder(tgt_input_idxs,hidden,encoder_outputs)\n",
    "        return outputs\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
